{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# HW6"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Dropout, Activation, MaxPooling2D, Flatten",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(Dense(4, input_shape=(6,), activation='tanh'))\nmodel.add(Dense(4, activation='tanh'))\nmodel.add(Dense(1, activation='tanh'))",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install mlxtend",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting mlxtend\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/d1/1b9e85e991f836e9aaea18367ff628a6324af1005971dc9f57e51a2ab5a4/mlxtend-0.14.0-py2.py3-none-any.whl (1.3MB)\n\u001b[K    100% |████████████████████████████████| 1.3MB 6.1MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: setuptools in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (40.6.2)\nRequirement already satisfied: scipy>=0.17 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (1.1.0)\nRequirement already satisfied: scikit-learn>=0.18 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (0.19.1)\nRequirement already satisfied: numpy>=1.10.4 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (1.15.4)\nRequirement already satisfied: matplotlib>=1.5.1 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (2.1.1)\nRequirement already satisfied: pandas>=0.17.1 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from mlxtend) (0.19.2)\nRequirement already satisfied: six>=1.10 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend) (1.11.0)\nRequirement already satisfied: python-dateutil>=2.0 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend) (2.7.5)\nRequirement already satisfied: pytz in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend) (2016.6.1)\nRequirement already satisfied: cycler>=0.10 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from matplotlib>=1.5.1->mlxtend) (2.1.4)\nInstalling collected packages: mlxtend\nSuccessfully installed mlxtend-0.14.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Read all EMNIST test and train data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from mlxtend.data import loadlocal_mnist\n\nX_train, y_train = loadlocal_mnist(\n        images_path=\"./emnist-balanced-train-images-idx3-ubyte\", \n        labels_path=\"./emnist-balanced-train-labels-idx1-ubyte\")\n\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from mlxtend.data import loadlocal_mnist\n\nX_test, y_test = loadlocal_mnist(\n        images_path=\"./emnist-balanced-test-images-idx3-ubyte\", \n        labels_path=\"./emnist-balanced-test-labels-idx1-ubyte\")",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Reading mapping of the labels and convert ASCII values to chars"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mapping = []\nwith open('./emnist-balanced-mapping.txt') as f:\n    for line in f:\n        mapping.append(chr(int(line.split()[1])))",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Converting data to numpy arrays and normalize images to the interval [0,1]"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train = np.array(X_train) / 255\ny_train = np.array(y_train)\nX_test = np.array(X_test) / 255\ny_test = np.array(y_test)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense\n\ndef build_model(nb_classes, nb_filters, kernel_size, pool_size, input_shape):\n    model = Sequential()\n    model.add(Convolution2D(int(nb_filters / 2), kernel_size, padding='valid',\n                            input_shape=input_shape, activation='relu',\n                            kernel_initializer='he_normal', data_format = 'channels_first'))\n    model.add(MaxPooling2D(pool_size=pool_size))\n    model.add(Convolution2D(nb_filters, kernel_size, activation='relu', \n                            kernel_initializer='he_normal', data_format = 'channels_first'))\n    model.add(MaxPooling2D(pool_size=pool_size))\n    \n    model.add(Flatten())\n    model.add(Dense(250, activation='relu', kernel_initializer='he_normal'))\n    model.add(Dropout(0.5))\n    model.add(Dense(125, activation='relu', kernel_initializer='he_normal'))\n    model.add(Dropout(0.5))\n    model.add(Dense(nb_classes, activation='softmax', kernel_initializer='he_normal'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n    print(model.summary())\n    \n    return model",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Setting the parameters to be used with our CNN and preprocess the data a bit further in order for it to be in the necessary shape.\n\nlen(mapping) is for number of classes in the train set \nnb_filters is number of convolutional filters\nour kernel size is (5,5) and pooling area is (2,2)\nWe reshaped the image size as 1,28,28 to be used in a Convolutional Neural Network\nWe need one-hot encoding of the label arrays\n\nThe Keras library offers a function called to_categorical() that you can use to one hot encode integer data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from keras.utils import np_utils\n\n\nnb_classes = len(mapping)\nnb_filters = 32\nkernel_size = (5, 5) \npool_size = (2, 2)\ninput_shape = (1, 28, 28)\n\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n\n\ny_train = np_utils.to_categorical(y_train, nb_classes)\ny_test = np_utils.to_categorical(y_test, nb_classes)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Building our CNN model and fit it with the EMNIST training data."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = build_model(nb_classes, nb_filters, kernel_size, pool_size, input_shape)\nmodel.fit(X_train, y_train, batch_size=128, epochs=12)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 16, 24, 24)        416       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 12, 24)         0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 8, 20)         6432      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 16, 4, 20)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1280)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 250)               320250    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 250)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 125)               31375     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 125)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 47)                5922      \n=================================================================\nTotal params: 364,395\nTrainable params: 364,395\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/12\n112800/112800 [==============================] - 255s - loss: 1.9869 - acc: 0.4377   \nEpoch 2/12\n112800/112800 [==============================] - 255s - loss: 1.0155 - acc: 0.6839   \nEpoch 3/12\n112800/112800 [==============================] - 259s - loss: 0.8207 - acc: 0.7383   \nEpoch 4/12\n112800/112800 [==============================] - 260s - loss: 0.7321 - acc: 0.7648   \nEpoch 5/12\n112800/112800 [==============================] - 256s - loss: 0.6739 - acc: 0.7817   \nEpoch 6/12\n112800/112800 [==============================] - 251s - loss: 0.6312 - acc: 0.7932   \nEpoch 7/12\n112800/112800 [==============================] - 252s - loss: 0.5978 - acc: 0.8041   \nEpoch 8/12\n112800/112800 [==============================] - 460s - loss: 0.5743 - acc: 0.8103   \nEpoch 9/12\n112800/112800 [==============================] - 543s - loss: 0.5527 - acc: 0.8176   \nEpoch 10/12\n112800/112800 [==============================] - 519s - loss: 0.5324 - acc: 0.8231   \nEpoch 11/12\n112800/112800 [==============================] - 433s - loss: 0.5192 - acc: 0.8258   \nEpoch 12/12\n112800/112800 [==============================] - 513s - loss: 0.5085 - acc: 0.8306   \n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f72ab911f60>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Evaluating our CNN with the test data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_eval = model.evaluate(X_test, y_test)\nprint()\nprint('    Test set loss:', test_eval[0])\nprint('Test set accuracy:', test_eval[1])",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "18800/18800 [==============================] - 60s    \n\n    Test set loss: 0.39020500284560183\nTest set accuracy: 0.8661170212765957\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "I trained it twice but it can be still trained more to have better accuracy."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}